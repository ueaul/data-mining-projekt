{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8182919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.copy(deep=True)\n",
    "target = df_features[\"salary_in_usd\"]\n",
    "df_features.drop([\"salary\", \"salary_in_usd\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778bfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHot_features = [\"work_year\", \"employment_type\", \"remote_ratio\", \"job_title\", \"salary_currency\", \"employee_residence\", \"company_location\",\"company_size\", \"experience_level\"]\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(), oneHot_features),\n",
    "    ])\n",
    "df_preprocessed = preprocessor.fit_transform(df_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e89269",
   "metadata": {},
   "source": [
    "# init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ceb6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a271667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       7.083341      0.229504         0.001964        0.000815   \n",
      "1       2.142308      3.250260         0.001305        0.000932   \n",
      "2       9.167933      0.355813         0.001907        0.004686   \n",
      "3       9.649185      0.256764         0.004894        0.007055   \n",
      "4      10.863007      0.241316         0.001782        0.004660   \n",
      "5      11.857682      0.131954         0.001562        0.004686   \n",
      "6       2.391625      0.714866         0.001563        0.004689   \n",
      "7       3.654594      2.669266         0.002046        0.004625   \n",
      "8       6.469462      0.216413         0.000000        0.000000   \n",
      "\n",
      "               param_hidden_layer_sizes param_solver  \\\n",
      "0                            (100, 100)        lbfgs   \n",
      "1                            (100, 100)          sgd   \n",
      "2                            (100, 100)         adam   \n",
      "3                       (100, 100, 100)        lbfgs   \n",
      "4                       (100, 100, 100)          sgd   \n",
      "5                       (100, 100, 100)         adam   \n",
      "6  (10, 10, 10, 10, 10, 10, 10, 10, 10)        lbfgs   \n",
      "7  (10, 10, 10, 10, 10, 10, 10, 10, 10)          sgd   \n",
      "8  (10, 10, 10, 10, 10, 10, 10, 10, 10)         adam   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'hidden_layer_sizes': (100, 100), 'solver': '...           0.394754   \n",
      "1  {'hidden_layer_sizes': (100, 100), 'solver': '...          -9.995549   \n",
      "2  {'hidden_layer_sizes': (100, 100), 'solver': '...           0.408266   \n",
      "3  {'hidden_layer_sizes': (100, 100, 100), 'solve...           0.387046   \n",
      "4  {'hidden_layer_sizes': (100, 100, 100), 'solve...                NaN   \n",
      "5  {'hidden_layer_sizes': (100, 100, 100), 'solve...           0.398981   \n",
      "6  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...           0.395403   \n",
      "7  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...                NaN   \n",
      "8  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...           0.403038   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0           0.383000       3.408678e-01       3.814935e-01           0.439625   \n",
      "1          -0.013004      -7.920349e+34      -4.349981e+13          -0.564236   \n",
      "2           0.432078       3.396137e-01       3.936347e-01           0.434133   \n",
      "3           0.365869       3.016546e-01       3.694478e-01           0.382767   \n",
      "4                NaN                NaN                NaN                NaN   \n",
      "5           0.429697       3.595907e-01       4.249133e-01           0.442692   \n",
      "6           0.428453       3.154920e-01       3.868261e-01           0.435844   \n",
      "7                NaN      -5.317177e-02      -5.982379e+03     -772616.156184   \n",
      "8           0.435267       3.660755e-01       4.227118e-01           0.443720   \n",
      "\n",
      "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
      "0       3.602878e-01       3.739783e-01       4.287898e-01       5.183303e-01   \n",
      "1      -7.123949e+36      -1.198423e+82      -5.135571e+11                NaN   \n",
      "2       3.589068e-01       4.039214e-01       4.005288e-01       5.398749e-01   \n",
      "3       3.488291e-01       3.909839e-01       3.937940e-01       5.316400e-01   \n",
      "4               -inf                NaN                NaN                NaN   \n",
      "5       3.567530e-01       4.586843e-01       4.318951e-01       5.513580e-01   \n",
      "6       3.714063e-01       4.338850e-01      -1.782483e-01       5.511752e-01   \n",
      "7     -1.757325e+228                NaN                NaN      -4.936640e+64   \n",
      "8       3.555662e-01       4.570109e-01       4.378871e-01       5.500862e-01   \n",
      "\n",
      "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.462643         0.408377        0.051023                4  \n",
      "1          -0.224775              NaN             NaN                7  \n",
      "2           0.462788         0.417375        0.053049                3  \n",
      "3           0.488281         0.396031        0.063197                5  \n",
      "4                NaN              NaN             NaN                8  \n",
      "5           0.485691         0.434025        0.054741                2  \n",
      "6           0.498580         0.363882        0.191127                6  \n",
      "7                NaN              NaN             NaN                9  \n",
      "8           0.486431         0.435779        0.053559                1  \n",
      "best score is 0.43577944334525787 with params {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10, 10, 10, 10), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\": [(100,100),(100,100,100),(10,10,10,10,10,10,10,10,10)],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "}\n",
    "\n",
    "#Pr√ºfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "print(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b44db0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       3.007595      0.246308         0.003574        0.006168   \n",
      "1       3.739567      3.059376         0.001563        0.004690   \n",
      "2       7.658335      0.809924         0.001411        0.003232   \n",
      "3      21.463450     11.794150         0.007254        0.007766   \n",
      "4      29.255870      0.610951         0.005954        0.002481   \n",
      "5      22.885223      4.246790         0.004817        0.005965   \n",
      "6       3.820160      1.749571         0.000157        0.000471   \n",
      "7       7.337113      2.241766         0.000000        0.000000   \n",
      "8       8.909608      0.559159         0.003129        0.006259   \n",
      "\n",
      "                            param_hidden_layer_sizes param_solver  \\\n",
      "0           (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)        lbfgs   \n",
      "1           (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)          sgd   \n",
      "2           (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)         adam   \n",
      "3  (100, 100, 100, 100, 100, 100, 100, 100, 100, ...        lbfgs   \n",
      "4  (100, 100, 100, 100, 100, 100, 100, 100, 100, ...          sgd   \n",
      "5  (100, 100, 100, 100, 100, 100, 100, 100, 100, ...         adam   \n",
      "6  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...        lbfgs   \n",
      "7  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...          sgd   \n",
      "8  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 1...         adam   \n",
      "\n",
      "                                              params  split0_test_score  \\\n",
      "0  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...       3.860758e-01   \n",
      "1  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...      -4.716043e+44   \n",
      "2  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...       3.922516e-01   \n",
      "3  {'hidden_layer_sizes': (100, 100, 100, 100, 10...       3.739358e-01   \n",
      "4  {'hidden_layer_sizes': (100, 100, 100, 100, 10...                NaN   \n",
      "5  {'hidden_layer_sizes': (100, 100, 100, 100, 10...       3.684269e-01   \n",
      "6  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...       3.792443e-01   \n",
      "7  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...                NaN   \n",
      "8  {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10...      -1.246370e-03   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0       4.238695e-01       3.505241e-01       3.675045e-01           0.434987   \n",
      "1      -3.722337e+49      -1.407612e+78     -1.357782e+275                NaN   \n",
      "2       4.319877e-01       3.628054e-01       4.303283e-01           0.436333   \n",
      "3       1.215963e-01       3.316014e-01      -2.639690e-01           0.379392   \n",
      "4                NaN                NaN                NaN                NaN   \n",
      "5       3.445975e-01       3.505874e-01       3.566459e-01           0.422119   \n",
      "6       4.228813e-01       3.302774e-01       3.972784e-01           0.442673   \n",
      "7                NaN      -1.143136e+50                NaN                NaN   \n",
      "8       4.148938e-01       3.570432e-01       3.929297e-01           0.447536   \n",
      "\n",
      "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
      "0           0.361071           0.441875           0.427373           0.546712   \n",
      "1                NaN                NaN          -0.008419                NaN   \n",
      "2           0.348013           0.428844           0.434902           0.552394   \n",
      "3           0.326836           0.345168           0.410259           0.531952   \n",
      "4                NaN                NaN                NaN                NaN   \n",
      "5           0.334913           0.351993           0.351079           0.520485   \n",
      "6          -0.218313           0.420149           0.430313           0.532584   \n",
      "7                NaN                NaN                NaN                NaN   \n",
      "8           0.360966           0.445103           0.434527           0.547541   \n",
      "\n",
      "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0       4.683112e-01         0.420830        0.056001                2  \n",
      "1      -5.294538e+20              NaN             NaN                7  \n",
      "2       4.862919e-01         0.430415        0.055569                1  \n",
      "3       1.334556e-01         0.269023        0.212018                6  \n",
      "4                NaN              NaN             NaN                8  \n",
      "5       4.435293e-01         0.384438        0.056392                4  \n",
      "6      -8.701055e-03         0.312839        0.223590                5  \n",
      "7                NaN              NaN             NaN                9  \n",
      "8       4.745094e-01         0.387380        0.139947                3  \n",
      "best score is 0.4304151550696965 with params {'hidden_layer_sizes': (10, 10, 10, 10, 10, 10, 10, 10, 10, 10), 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\": [(10,10,10,10,10,10,10,10,10,10),(100,100,100,100,100,100,100,100,100,100),(10,10,10,10,10,10,10,10,10,10,10,10,10,10,10)],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "}\n",
    "\n",
    "#Pr√ºfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "print(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc7013f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        4.246095      1.632716         0.002412        0.004962   \n",
      "1        7.100611      5.234726         0.008517        0.024686   \n",
      "2       11.545283      0.516901         0.004638        0.006684   \n",
      "3        3.878314      0.871142         0.001373        0.002326   \n",
      "4        8.076966      3.745631         0.003615        0.006247   \n",
      "5       11.169790      0.159624         0.006259        0.007278   \n",
      "6        4.120060      1.420632         0.002943        0.005465   \n",
      "7        9.771756      3.243771         0.002345        0.004020   \n",
      "8       11.535240      0.337262         0.001594        0.003189   \n",
      "9        2.898957      2.102729         0.002390        0.003944   \n",
      "10       8.135888      3.769954         0.003018        0.005912   \n",
      "11      11.280966      0.216501         0.001471        0.003480   \n",
      "12       3.868546      1.226026         0.003964        0.006323   \n",
      "13       8.344215      3.861091         0.007226        0.006896   \n",
      "14      10.713620      1.924341         0.003117        0.006233   \n",
      "15       4.055190      1.221601         0.003182        0.006112   \n",
      "16       8.532595      2.573949         0.000552        0.001655   \n",
      "17      11.195517      0.186736         0.003668        0.006069   \n",
      "18       3.215874      1.813725         0.001770        0.004658   \n",
      "19       7.983511      3.673582         0.002850        0.005144   \n",
      "20      11.043407      0.658402         0.005874        0.007451   \n",
      "21       4.345307      0.559618         0.001305        0.003915   \n",
      "22       8.086061      3.729277         0.003751        0.006058   \n",
      "23      11.272735      0.134438         0.003318        0.006179   \n",
      "24       3.913119      1.196048         0.003124        0.006248   \n",
      "25       7.364273      3.232977         0.000924        0.001956   \n",
      "26      11.261873      0.134638         0.000103        0.000309   \n",
      "27       0.579460      0.196756         0.001554        0.002694   \n",
      "28       1.144738      0.167079         0.003910        0.005157   \n",
      "29      13.040919      0.273962         0.003779        0.004854   \n",
      "30       0.740432      0.136784         0.001797        0.004674   \n",
      "31       0.740004      0.041611         0.000501        0.001504   \n",
      "32      12.941189      0.312758         0.003608        0.006167   \n",
      "33       0.621897      0.195205         0.001774        0.004659   \n",
      "34       5.215883      1.702520         0.002653        0.004757   \n",
      "35      12.757625      0.311230         0.005139        0.006983   \n",
      "36       1.031348      0.206186         0.003932        0.006115   \n",
      "37       1.258561      0.317095         0.001416        0.002421   \n",
      "38      13.042672      0.336739         0.004598        0.005760   \n",
      "39       0.917382      0.196642         0.005402        0.006865   \n",
      "40       1.718094      2.973713         0.007648        0.006676   \n",
      "41      13.114244      0.507053         0.002534        0.003498   \n",
      "42       0.954297      0.177798         0.000663        0.001040   \n",
      "43       5.300341      1.047621         0.001985        0.002322   \n",
      "44      12.929588      0.342407         0.004158        0.005841   \n",
      "45       0.771223      0.274902         0.000556        0.001159   \n",
      "46       1.256637      0.444762         0.005409        0.005945   \n",
      "47      12.674132      0.385314         0.002312        0.003210   \n",
      "48       0.971316      0.375986         0.001602        0.004805   \n",
      "49       0.682102      0.029123         0.004504        0.004926   \n",
      "50      12.348971      0.131171         0.002272        0.004616   \n",
      "51       0.970148      0.251809         0.003033        0.003414   \n",
      "52       5.042854      1.109796         0.001924        0.002736   \n",
      "53      12.351706      0.076743         0.003253        0.003093   \n",
      "\n",
      "   param_activation param_alpha                  param_hidden_layer_sizes  \\\n",
      "0              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "1              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "2              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "3              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "4              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "5              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "6              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "7              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "8              relu      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "9              relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "10             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "11             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "12             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "13             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "14             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "15             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "16             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "17             relu       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "18             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "19             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "20             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "21             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "22             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "23             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "24             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "25             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "26             relu        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "27             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "28             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "29             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "30             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "31             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "32             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "33             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "34             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "35             tanh      0.0001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "36             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "37             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "38             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "39             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "40             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "41             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "42             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "43             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "44             tanh       0.001  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "45             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "46             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "47             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "48             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "49             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "50             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "51             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "52             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "53             tanh        0.01  (10, 10, 10, 10, 10, 10, 10, 10, 10, 10)   \n",
      "\n",
      "   param_learning_rate param_solver  \\\n",
      "0             constant        lbfgs   \n",
      "1             constant          sgd   \n",
      "2             constant         adam   \n",
      "3           invscaling        lbfgs   \n",
      "4           invscaling          sgd   \n",
      "5           invscaling         adam   \n",
      "6             adaptive        lbfgs   \n",
      "7             adaptive          sgd   \n",
      "8             adaptive         adam   \n",
      "9             constant        lbfgs   \n",
      "10            constant          sgd   \n",
      "11            constant         adam   \n",
      "12          invscaling        lbfgs   \n",
      "13          invscaling          sgd   \n",
      "14          invscaling         adam   \n",
      "15            adaptive        lbfgs   \n",
      "16            adaptive          sgd   \n",
      "17            adaptive         adam   \n",
      "18            constant        lbfgs   \n",
      "19            constant          sgd   \n",
      "20            constant         adam   \n",
      "21          invscaling        lbfgs   \n",
      "22          invscaling          sgd   \n",
      "23          invscaling         adam   \n",
      "24            adaptive        lbfgs   \n",
      "25            adaptive          sgd   \n",
      "26            adaptive         adam   \n",
      "27            constant        lbfgs   \n",
      "28            constant          sgd   \n",
      "29            constant         adam   \n",
      "30          invscaling        lbfgs   \n",
      "31          invscaling          sgd   \n",
      "32          invscaling         adam   \n",
      "33            adaptive        lbfgs   \n",
      "34            adaptive          sgd   \n",
      "35            adaptive         adam   \n",
      "36            constant        lbfgs   \n",
      "37            constant          sgd   \n",
      "38            constant         adam   \n",
      "39          invscaling        lbfgs   \n",
      "40          invscaling          sgd   \n",
      "41          invscaling         adam   \n",
      "42            adaptive        lbfgs   \n",
      "43            adaptive          sgd   \n",
      "44            adaptive         adam   \n",
      "45            constant        lbfgs   \n",
      "46            constant          sgd   \n",
      "47            constant         adam   \n",
      "48          invscaling        lbfgs   \n",
      "49          invscaling          sgd   \n",
      "50          invscaling         adam   \n",
      "51            adaptive        lbfgs   \n",
      "52            adaptive          sgd   \n",
      "53            adaptive         adam   \n",
      "\n",
      "                                               params  ...  split3_test_score  \\\n",
      "0   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...      -4.015981e-03   \n",
      "1   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...                NaN   \n",
      "2   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...       4.068437e-01   \n",
      "3   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...       2.950001e-01   \n",
      "4   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...                NaN   \n",
      "5   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...      -4.713513e+00   \n",
      "6   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...       3.809436e-01   \n",
      "7   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...      -1.040679e+03   \n",
      "8   {'activation': 'relu', 'alpha': 0.0001, 'hidde...  ...       4.196833e-01   \n",
      "9   {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...       4.124943e-01   \n",
      "10  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...                NaN   \n",
      "11  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...       4.048427e-01   \n",
      "12  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...      -3.934897e-03   \n",
      "13  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...                NaN   \n",
      "14  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...       4.152205e-01   \n",
      "15  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...       3.806063e-01   \n",
      "16  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...     -2.934971e+222   \n",
      "17  {'activation': 'relu', 'alpha': 0.001, 'hidden...  ...       4.113158e-01   \n",
      "18  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       2.727521e-02   \n",
      "19  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...      -1.065107e+02   \n",
      "20  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       4.208767e-01   \n",
      "21  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       3.744688e-01   \n",
      "22  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...                NaN   \n",
      "23  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       4.157101e-01   \n",
      "24  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       4.089863e-01   \n",
      "25  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...                NaN   \n",
      "26  {'activation': 'relu', 'alpha': 0.01, 'hidden_...  ...       4.236040e-01   \n",
      "27  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -3.934879e-03   \n",
      "28  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -3.769421e-03   \n",
      "29  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -4.717452e+00   \n",
      "30  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -3.934875e-03   \n",
      "31  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -7.738381e-02   \n",
      "32  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -4.717401e+00   \n",
      "33  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -3.934879e-03   \n",
      "34  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -3.924666e-03   \n",
      "35  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...  ...      -4.717388e+00   \n",
      "36  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -3.934885e-03   \n",
      "37  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -3.788652e-03   \n",
      "38  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -4.717547e+00   \n",
      "39  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -3.934883e-03   \n",
      "40  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -7.108712e-02   \n",
      "41  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -4.717533e+00   \n",
      "42  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -3.934883e-03   \n",
      "43  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -3.956735e-03   \n",
      "44  {'activation': 'tanh', 'alpha': 0.001, 'hidden...  ...      -4.717474e+00   \n",
      "45  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -3.934903e-03   \n",
      "46  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -3.879238e-03   \n",
      "47  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -4.717385e+00   \n",
      "48  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -3.934927e-03   \n",
      "49  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -8.735637e-02   \n",
      "50  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -4.717391e+00   \n",
      "51  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -3.934894e-03   \n",
      "52  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -3.963948e-03   \n",
      "53  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...  ...      -4.717417e+00   \n",
      "\n",
      "    split4_test_score  split5_test_score  split6_test_score  \\\n",
      "0        4.300451e-01       3.583783e-01       4.242619e-01   \n",
      "1      -2.496835e+143                NaN                NaN   \n",
      "2        4.434517e-01       3.532303e-01       4.576073e-01   \n",
      "3        4.461415e-01       3.508310e-01       3.958535e-01   \n",
      "4                 NaN                NaN      -1.735555e+21   \n",
      "5        4.313880e-01       3.573279e-01       4.516285e-01   \n",
      "6        4.393560e-01       3.685147e-01       4.031865e-01   \n",
      "7                 NaN                NaN      -3.185967e+01   \n",
      "8        4.478023e-01       3.556814e-01       4.541627e-01   \n",
      "9        4.347229e-01       3.713981e-01       7.498793e-02   \n",
      "10                NaN     -1.124615e+150                NaN   \n",
      "11       4.532493e-01       3.550461e-01       4.439468e-01   \n",
      "12       4.109676e-01       3.814717e-01       4.137924e-01   \n",
      "13                NaN                NaN      -6.061127e+04   \n",
      "14       4.381148e-01       3.553437e-01      -1.125179e-04   \n",
      "15      -1.859400e-02       3.659166e-01       4.335664e-01   \n",
      "16                NaN                NaN                NaN   \n",
      "17       4.412869e-01       3.575500e-01       4.593180e-01   \n",
      "18       4.218407e-01       3.513106e-01       4.335328e-01   \n",
      "19                NaN                NaN                NaN   \n",
      "20       4.429796e-01       3.561027e-01       4.539231e-01   \n",
      "21       4.332108e-01       3.568504e-01       4.274781e-01   \n",
      "22      -6.225292e+31                NaN                NaN   \n",
      "23       4.379711e-01       3.554656e-01       4.395727e-01   \n",
      "24       4.319845e-01       3.336396e-01       4.027400e-01   \n",
      "25      -2.535265e+71                NaN                NaN   \n",
      "26       4.473301e-01       3.465380e-01       4.536430e-01   \n",
      "27      -7.631266e-04      -1.712852e-04      -5.830686e-05   \n",
      "28      -1.193528e-03      -1.486966e-04      -8.025207e-06   \n",
      "29      -5.194839e+00      -4.627411e+00      -5.024186e+00   \n",
      "30      -7.631167e-04      -1.712137e-04      -5.831643e-05   \n",
      "31      -1.142604e-01      -9.771765e-02      -1.415279e-01   \n",
      "32      -5.195104e+00      -4.627458e+00      -5.024235e+00   \n",
      "33      -7.631224e-04      -1.712517e-04      -5.831580e-05   \n",
      "34      -7.253015e-04      -1.647803e-04      -5.728376e-05   \n",
      "35      -5.195017e+00      -4.627570e+00      -5.024212e+00   \n",
      "36      -7.631177e-04      -1.712977e-04      -5.831656e-05   \n",
      "37      -6.186779e-04      -2.135149e-05      -7.094136e-05   \n",
      "38      -5.195066e+00      -4.627470e+00      -5.024271e+00   \n",
      "39      -7.631241e-04      -1.712453e-04      -5.831426e-05   \n",
      "40      -1.177695e-01      -1.133833e-01      -1.408526e-01   \n",
      "41      -5.195095e+00      -4.627569e+00      -5.024172e+00   \n",
      "42      -7.631236e-04      -1.712602e-04      -5.831479e-05   \n",
      "43      -7.851908e-04      -1.594368e-04      -5.691104e-05   \n",
      "44      -5.194976e+00      -4.627419e+00      -5.024183e+00   \n",
      "45      -7.631142e-04      -1.712887e-04      -5.830099e-05   \n",
      "46      -7.096932e-04      -2.500493e-04      -1.517460e-04   \n",
      "47      -5.195071e+00      -4.627386e+00      -5.024280e+00   \n",
      "48      -7.631025e-04      -1.713026e-04      -5.831298e-05   \n",
      "49      -9.558698e-02      -9.553841e-02      -1.326843e-01   \n",
      "50      -5.194955e+00      -4.627565e+00      -5.024121e+00   \n",
      "51      -7.631163e-04      -1.712936e-04      -5.830963e-05   \n",
      "52      -7.730611e-04      -1.688293e-04      -5.447488e-05   \n",
      "53      -5.195041e+00      -4.627462e+00      -5.024168e+00   \n",
      "\n",
      "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
      "0        4.439776e-01       5.433396e-01       4.834305e-01         0.325526   \n",
      "1      -1.026946e+197                NaN                NaN              NaN   \n",
      "2        4.328804e-01       5.520032e-01       4.865557e-01         0.432716   \n",
      "3        4.174555e-01       5.279708e-01       4.844836e-01         0.390992   \n",
      "4                 NaN      -4.262527e+04                NaN              NaN   \n",
      "5        4.337243e-01       5.536128e-01       4.884221e-01        -0.081650   \n",
      "6        4.188030e-01       3.881906e-01       4.925194e-01         0.359405   \n",
      "7                 NaN                NaN                NaN              NaN   \n",
      "8        4.331539e-01       5.490188e-01       4.815933e-01         0.433760   \n",
      "9       -8.395655e-03       4.841697e-01      -7.596337e-02         0.243580   \n",
      "10                NaN                NaN      -6.506902e+49              NaN   \n",
      "11       4.348250e-01       5.524487e-01       4.853205e-01         0.433259   \n",
      "12       4.342988e-01       5.497559e-01       5.075706e-01         0.381324   \n",
      "13                NaN                NaN                NaN              NaN   \n",
      "14       4.315812e-01       5.520068e-01       4.860679e-01         0.387337   \n",
      "15       4.249613e-01       4.654554e-01       4.918682e-01         0.361013   \n",
      "16      -8.432139e-03                NaN                NaN              NaN   \n",
      "17       4.363660e-01       5.530505e-01       4.884180e-01         0.434383   \n",
      "18       4.279121e-01      -1.691350e-02       4.991083e-01         0.296245   \n",
      "19      -2.856576e+18                NaN                NaN              NaN   \n",
      "20      -4.898837e+00       5.579450e-01       4.846312e-01        -0.099136   \n",
      "21       4.129085e-01       5.608418e-01       4.787449e-01         0.416298   \n",
      "22               -inf      -4.092491e+15                NaN              NaN   \n",
      "23       4.278390e-01       5.483674e-01       4.828525e-01         0.430271   \n",
      "24       4.278439e-01       5.556267e-01       4.701833e-01         0.371592   \n",
      "25     -3.173898e+182                NaN     -1.979034e+153              NaN   \n",
      "26       4.338317e-01       5.549976e-01       4.833437e-01         0.433182   \n",
      "27      -8.395656e-03      -9.132533e-03      -2.825777e-03        -0.004050   \n",
      "28      -8.247679e-03      -8.996988e-03      -2.533738e-03        -0.004032   \n",
      "29      -4.901152e+00      -4.432635e+00      -4.694050e+00        -4.782624   \n",
      "30      -8.395654e-03      -9.132466e-03      -2.825807e-03        -0.004049   \n",
      "31      -5.951298e-02      -1.890642e-01      -1.428746e-01        -0.118786   \n",
      "32      -4.901135e+00      -4.432640e+00      -4.694097e+00        -4.782652   \n",
      "33      -8.395653e-03      -9.132504e-03      -2.825793e-03        -0.004050   \n",
      "34      -8.383418e-03      -9.162038e-03      -2.853941e-03        -0.004041   \n",
      "35      -4.901118e+00      -4.432569e+00      -4.694096e+00        -4.782639   \n",
      "36      -8.395656e-03      -9.132513e-03      -2.825793e-03        -0.004050   \n",
      "37      -8.404564e-03      -9.109897e-03      -2.119706e-03        -0.003902   \n",
      "38      -4.901101e+00      -4.432562e+00      -4.694131e+00        -4.782658   \n",
      "39      -8.395834e-03      -9.132522e-03      -2.825770e-03        -0.004050   \n",
      "40      -7.310410e-02      -1.911120e-01      -1.034091e-01        -0.117548   \n",
      "41      -4.901167e+00      -4.432763e+00      -4.694049e+00        -4.782668   \n",
      "42      -8.395643e-03      -9.132527e-03      -2.825788e-03        -0.004050   \n",
      "43      -8.319504e-03      -9.106130e-03      -2.850813e-03        -0.004037   \n",
      "44      -4.901059e+00      -4.432528e+00      -4.694202e+00        -4.782626   \n",
      "45      -8.395609e-03      -9.133372e-03      -2.822124e-03        -0.004050   \n",
      "46      -7.229283e-03      -9.884363e-03      -2.422533e-03        -0.004136   \n",
      "47      -4.901182e+00      -4.432631e+00      -4.694214e+00        -4.782648   \n",
      "48      -8.395683e-03      -9.132505e-03      -2.825683e-03        -0.004050   \n",
      "49      -6.332286e-02      -1.962125e-01      -1.541165e-01        -0.126456   \n",
      "50      -4.901092e+00      -4.432556e+00      -4.694156e+00        -4.782624   \n",
      "51      -8.395860e-03      -9.132499e-03      -2.830611e-03        -0.004050   \n",
      "52      -8.380182e-03      -9.155824e-03      -2.843345e-03        -0.004054   \n",
      "53      -4.901100e+00      -4.432690e+00      -4.694104e+00        -4.782644   \n",
      "\n",
      "    std_test_score  rank_test_score  \n",
      "0         0.209548               14  \n",
      "1              NaN               48  \n",
      "2         0.056426                5  \n",
      "3         0.076084                8  \n",
      "4              NaN               49  \n",
      "5         1.544927               32  \n",
      "6         0.132006               13  \n",
      "7              NaN               52  \n",
      "8         0.053365                2  \n",
      "9         0.206902               16  \n",
      "10             NaN               54  \n",
      "11        0.054316                3  \n",
      "12        0.142576               10  \n",
      "13             NaN               46  \n",
      "14        0.140037                9  \n",
      "15        0.135563               12  \n",
      "16             NaN               53  \n",
      "17        0.055543                1  \n",
      "18        0.172080               15  \n",
      "19             NaN               51  \n",
      "20        1.600916               33  \n",
      "21        0.063229                7  \n",
      "22             NaN               50  \n",
      "23        0.053335                6  \n",
      "24        0.164102               11  \n",
      "25             NaN               47  \n",
      "26        0.056752                4  \n",
      "27        0.004347               27  \n",
      "28        0.004421               18  \n",
      "29        0.215325               37  \n",
      "30        0.004348               21  \n",
      "31        0.054975               35  \n",
      "32        0.215376               43  \n",
      "33        0.004347               26  \n",
      "34        0.004330               20  \n",
      "35        0.215347               40  \n",
      "36        0.004347               25  \n",
      "37        0.004244               17  \n",
      "38        0.215368               44  \n",
      "39        0.004347               28  \n",
      "40        0.055969               34  \n",
      "41        0.215324               45  \n",
      "42        0.004347               24  \n",
      "43        0.004326               19  \n",
      "44        0.215343               39  \n",
      "45        0.004347               22  \n",
      "46        0.004629               31  \n",
      "47        0.215362               42  \n",
      "48        0.004347               23  \n",
      "49        0.052125               36  \n",
      "50        0.215326               38  \n",
      "51        0.004347               29  \n",
      "52        0.004346               30  \n",
      "53        0.215342               41  \n",
      "\n",
      "[54 rows x 23 columns]\n",
      "best score is 0.4343828809617204 with params {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (10, 10, 10, 10, 10, 10, 10, 10, 10, 10), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\": [(10,10,10,10,10,10,10,10,10,10)],\n",
    "    \"solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "}\n",
    "\n",
    "#Pr√ºfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "print(results)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c8a51c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
