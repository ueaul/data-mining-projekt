{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8182919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../Dataset/ds_salaries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e1505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df.copy(deep=True)\n",
    "target = df_features[\"salary_in_usd\"]\n",
    "df_features.drop([\"salary\", \"salary_in_usd\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "778bfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHot_features = [\"work_year\", \"employment_type\", \"remote_ratio\", \"job_title\", \"salary_currency\", \"employee_residence\", \"company_location\",\"company_size\", \"experience_level\"]\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', OneHotEncoder(), oneHot_features),\n",
    "    ])\n",
    "df_preprocessed = preprocessor.fit_transform(df_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e89269",
   "metadata": {},
   "source": [
    "# init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ceb6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a271667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.4077028361552717 with params {'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "}\n",
    "\n",
    "#Prüfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "#results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42caa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.4203945711812123 with params {'activation': 'relu', 'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.359060      0.056244         0.000356        0.000048   \n",
      "1        0.172836      0.119280         0.000336        0.000023   \n",
      "2        0.950425      0.009166         0.000336        0.000023   \n",
      "3        1.456380      0.352923         0.000498        0.000058   \n",
      "4        0.382040      0.218482         0.000584        0.000282   \n",
      "5        2.109464      0.136969         0.000609        0.000135   \n",
      "6        1.895033      0.053281         0.000708        0.000298   \n",
      "7        0.544295      0.353388         0.000706        0.000377   \n",
      "8        3.977745      0.420531         0.000842        0.000466   \n",
      "9        0.084674      0.031386         0.000320        0.000024   \n",
      "10       0.093329      0.033609         0.000319        0.000027   \n",
      "11       1.019714      0.006413         0.000380        0.000014   \n",
      "12       0.352859      0.418483         0.000628        0.000218   \n",
      "13       0.231701      0.083131         0.000615        0.000179   \n",
      "14       2.858710      0.522091         0.000956        0.000371   \n",
      "15       0.361761      0.308244         0.000781        0.000188   \n",
      "16       0.489949      0.182976         0.000714        0.000179   \n",
      "17       4.269845      0.267005         0.000899        0.000044   \n",
      "\n",
      "   param_activation param_hidden_layer_sizes param_solver  \\\n",
      "0              relu                    (10,)        lbfgs   \n",
      "1              relu                    (10,)          sgd   \n",
      "2              relu                    (10,)         adam   \n",
      "3              relu                    (50,)        lbfgs   \n",
      "4              relu                    (50,)          sgd   \n",
      "5              relu                    (50,)         adam   \n",
      "6              relu                   (100,)        lbfgs   \n",
      "7              relu                   (100,)          sgd   \n",
      "8              relu                   (100,)         adam   \n",
      "9              tanh                    (10,)        lbfgs   \n",
      "10             tanh                    (10,)          sgd   \n",
      "11             tanh                    (10,)         adam   \n",
      "12             tanh                    (50,)        lbfgs   \n",
      "13             tanh                    (50,)          sgd   \n",
      "14             tanh                    (50,)         adam   \n",
      "15             tanh                   (100,)        lbfgs   \n",
      "16             tanh                   (100,)          sgd   \n",
      "17             tanh                   (100,)         adam   \n",
      "\n",
      "                                               params  split0_test_score  \\\n",
      "0   {'activation': 'relu', 'hidden_layer_sizes': (...           0.400557   \n",
      "1   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.001267   \n",
      "2   {'activation': 'relu', 'hidden_layer_sizes': (...          -4.466936   \n",
      "3   {'activation': 'relu', 'hidden_layer_sizes': (...           0.388742   \n",
      "4   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.001163   \n",
      "5   {'activation': 'relu', 'hidden_layer_sizes': (...          -4.072731   \n",
      "6   {'activation': 'relu', 'hidden_layer_sizes': (...           0.373100   \n",
      "7   {'activation': 'relu', 'hidden_layer_sizes': (...          -0.001222   \n",
      "8   {'activation': 'relu', 'hidden_layer_sizes': (...          -3.670854   \n",
      "9   {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.001207   \n",
      "10  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.001177   \n",
      "11  {'activation': 'tanh', 'hidden_layer_sizes': (...          -4.556090   \n",
      "12  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.001207   \n",
      "13  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.000171   \n",
      "14  {'activation': 'tanh', 'hidden_layer_sizes': (...          -4.546361   \n",
      "15  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.001207   \n",
      "16  {'activation': 'tanh', 'hidden_layer_sizes': (...          -0.001838   \n",
      "17  {'activation': 'tanh', 'hidden_layer_sizes': (...          -4.534584   \n",
      "\n",
      "    split1_test_score  ...  split3_test_score  split4_test_score  \\\n",
      "0            0.411908  ...       3.912331e-01           0.428749   \n",
      "1           -0.013090  ...      -3.594931e+02          -0.000778   \n",
      "2           -4.740372  ...      -4.625212e+00          -5.092226   \n",
      "3            0.397067  ...       3.774413e-01           0.434897   \n",
      "4           -0.013179  ...      -9.539114e+06          -0.000770   \n",
      "5           -4.345303  ...      -4.340322e+00          -4.754999   \n",
      "6            0.367844  ...       3.608923e-01           0.422097   \n",
      "7           -0.012988  ...      -3.881596e-03          -0.149331   \n",
      "8           -3.856756  ...      -3.873090e+00          -4.149760   \n",
      "9           -0.013146  ...      -3.934887e-03          -0.000763   \n",
      "10          -0.013840  ...      -4.413100e-03          -0.000497   \n",
      "11          -4.789645  ...      -4.717365e+00          -5.195149   \n",
      "12          -0.013146  ...       1.292107e-01           0.203277   \n",
      "13          -0.030014  ...      -5.848791e-03          -0.000192   \n",
      "14          -4.778908  ...      -4.707561e+00          -5.183965   \n",
      "15          -0.013146  ...       1.453931e-01          -0.000763   \n",
      "16          -0.012405  ...      -4.818409e-03          -0.004671   \n",
      "17          -4.765614  ...      -4.695566e+00          -5.170539   \n",
      "\n",
      "    split5_test_score  split6_test_score  split7_test_score  \\\n",
      "0            0.345293       4.263841e-01           0.408960   \n",
      "1           -0.000177      -3.855842e+04          -0.008392   \n",
      "2           -4.519711      -4.922430e+00          -4.838016   \n",
      "3            0.363374       4.063603e-01           0.394628   \n",
      "4        -4551.278497      -5.307766e-05          -0.008450   \n",
      "5           -4.145559      -4.592172e+00          -4.481562   \n",
      "6            0.363584       4.134670e-01           0.409959   \n",
      "7        -2733.139268      -5.126723e-05      -49720.499778   \n",
      "8           -3.823364      -4.023344e+00          -4.023736   \n",
      "9            0.156145      -5.831245e-05          -0.008396   \n",
      "10          -0.000241      -1.027562e-04          -0.009471   \n",
      "11          -4.627449      -5.024197e+00          -4.901135   \n",
      "12          -0.000171      -5.831549e-05           0.041690   \n",
      "13          -0.001087      -7.671801e-07          -0.008914   \n",
      "14          -4.617530      -5.013320e+00          -4.891023   \n",
      "15           0.145381      -5.831554e-05          -0.008396   \n",
      "16          -0.000810       1.340925e-01          -0.004327   \n",
      "17          -4.605567      -5.000008e+00          -4.878585   \n",
      "\n",
      "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
      "0            0.556165           0.482722         0.420395    5.847416e-02   \n",
      "1       -30186.529585         -22.983832    -10869.962822    1.668084e+04   \n",
      "2           -4.339478          -4.582054        -4.691836    2.163521e-01   \n",
      "3            0.556718           0.495675         0.414610    6.291733e-02   \n",
      "4         -851.725740       -6204.308508   -955072.127096    2.861348e+06   \n",
      "5           -4.085304          -4.208608        -4.345656    2.133162e-01   \n",
      "6            0.549337           0.485694         0.410050    6.007054e-02   \n",
      "7           -0.008949       -4841.115373    -10977.001947    2.012889e+04   \n",
      "8           -3.559866          -3.742534        -3.874078    1.736226e-01   \n",
      "9           -0.009133           0.140456         0.028496    6.079310e-02   \n",
      "10          -0.009158          -0.002460        -0.004219    4.636945e-03   \n",
      "11          -4.432573          -4.694042        -4.782612    2.153766e-01   \n",
      "12          -0.009133          -0.002826         0.049555    7.572474e-02   \n",
      "13          -0.005861          -0.000524        -0.005850    8.618733e-03   \n",
      "14          -4.422683          -4.683739        -4.772334    2.149860e-01   \n",
      "15          -0.009133          -0.002826         0.025438    6.011753e-02   \n",
      "16          -0.014871          -0.005539         0.007898    4.226651e-02   \n",
      "17          -4.410573          -4.671078        -4.759765    2.145218e-01   \n",
      "\n",
      "    rank_test_score  \n",
      "0                 1  \n",
      "1                16  \n",
      "2                12  \n",
      "3                 2  \n",
      "4                18  \n",
      "5                11  \n",
      "6                 3  \n",
      "7                17  \n",
      "8                10  \n",
      "9                 5  \n",
      "10                8  \n",
      "11               15  \n",
      "12                4  \n",
      "13                9  \n",
      "14               14  \n",
      "15                6  \n",
      "16                7  \n",
      "17               13  \n",
      "\n",
      "[18 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\" : [(10,), (50,), (100,)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "}\n",
    "\n",
    "#Prüfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "#results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d1c2186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.42103698335464906 with params {'activation': 'relu', 'alpha': 0.0001, 'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        0.379525      0.052288         0.000383        0.000091   \n",
      "1        0.078102      0.063745         0.000365        0.000100   \n",
      "2        0.988169      0.028414         0.000344        0.000021   \n",
      "3        1.514751      0.403496         0.000536        0.000097   \n",
      "4        0.423319      0.306813         0.000781        0.000487   \n",
      "5        2.113150      0.144979         0.000689        0.000283   \n",
      "6        1.999705      0.151223         0.001316        0.001748   \n",
      "7        0.837871      0.447839         0.001034        0.001167   \n",
      "8        3.902309      0.403383         0.001050        0.000655   \n",
      "9        0.331322      0.028712         0.000342        0.000013   \n",
      "10       0.147233      0.144952         0.000333        0.000014   \n",
      "11       1.078147      0.077091         0.000331        0.000016   \n",
      "12       1.326242      0.222619         0.000944        0.000653   \n",
      "13       0.408121      0.203699         0.000462        0.000043   \n",
      "14       2.075309      0.190729         0.000571        0.000179   \n",
      "15       2.079824      0.252010         0.000849        0.000650   \n",
      "16       0.725800      0.277850         0.000617        0.000195   \n",
      "17       3.835623      0.509426         0.001102        0.001037   \n",
      "18       0.395952      0.057891         0.000342        0.000019   \n",
      "19       0.075639      0.053805         0.000316        0.000026   \n",
      "20       1.101704      0.100306         0.000402        0.000192   \n",
      "21       1.535136      0.217440         0.000787        0.000681   \n",
      "22       0.626276      0.630299         0.000635        0.000462   \n",
      "23       2.321549      0.303673         0.000568        0.000201   \n",
      "24       2.007352      0.137496         0.000642        0.000127   \n",
      "25       0.911096      0.674328         0.000600        0.000147   \n",
      "26       4.074100      0.274302         0.001282        0.001548   \n",
      "27       0.135139      0.141789         0.000362        0.000034   \n",
      "28       0.098423      0.015242         0.000339        0.000014   \n",
      "29       1.029983      0.014209         0.000379        0.000020   \n",
      "30       0.662833      0.764277         0.000733        0.000335   \n",
      "31       0.191488      0.041633         0.000531        0.000098   \n",
      "32       2.362744      0.163680         0.000719        0.000146   \n",
      "33       0.430628      0.805107         0.000801        0.000217   \n",
      "34       0.353650      0.089532         0.000645        0.000031   \n",
      "35       4.083979      0.159235         0.001130        0.000389   \n",
      "36       0.158953      0.245686         0.000343        0.000016   \n",
      "37       0.098185      0.031146         0.000300        0.000044   \n",
      "38       1.004515      0.007319         0.000361        0.000018   \n",
      "39       0.820214      0.763314         0.000876        0.000442   \n",
      "40       0.225982      0.045984         0.000601        0.000085   \n",
      "41       2.605601      0.234765         0.000800        0.000221   \n",
      "42       1.062714      1.610646         0.000800        0.000164   \n",
      "43       0.392925      0.122168         0.000689        0.000080   \n",
      "44       4.250614      0.313505         0.000970        0.000229   \n",
      "45       0.130866      0.112788         0.000330        0.000012   \n",
      "46       0.112317      0.034261         0.000341        0.000026   \n",
      "47       1.068323      0.043427         0.000362        0.000018   \n",
      "48       0.408740      0.505294         0.000593        0.000079   \n",
      "49       0.237948      0.057335         0.000889        0.000976   \n",
      "50       2.288831      0.163796         0.000810        0.000192   \n",
      "51       0.926947      1.226486         0.000901        0.000333   \n",
      "52       0.454702      0.108483         0.001939        0.001942   \n",
      "53       4.380299      0.385280         0.000926        0.000113   \n",
      "\n",
      "   param_activation param_alpha param_hidden_layer_sizes param_solver  \\\n",
      "0              relu      0.0001                    (10,)        lbfgs   \n",
      "1              relu      0.0001                    (10,)          sgd   \n",
      "2              relu      0.0001                    (10,)         adam   \n",
      "3              relu      0.0001                    (50,)        lbfgs   \n",
      "4              relu      0.0001                    (50,)          sgd   \n",
      "5              relu      0.0001                    (50,)         adam   \n",
      "6              relu      0.0001                   (100,)        lbfgs   \n",
      "7              relu      0.0001                   (100,)          sgd   \n",
      "8              relu      0.0001                   (100,)         adam   \n",
      "9              relu       0.001                    (10,)        lbfgs   \n",
      "10             relu       0.001                    (10,)          sgd   \n",
      "11             relu       0.001                    (10,)         adam   \n",
      "12             relu       0.001                    (50,)        lbfgs   \n",
      "13             relu       0.001                    (50,)          sgd   \n",
      "14             relu       0.001                    (50,)         adam   \n",
      "15             relu       0.001                   (100,)        lbfgs   \n",
      "16             relu       0.001                   (100,)          sgd   \n",
      "17             relu       0.001                   (100,)         adam   \n",
      "18             relu        0.01                    (10,)        lbfgs   \n",
      "19             relu        0.01                    (10,)          sgd   \n",
      "20             relu        0.01                    (10,)         adam   \n",
      "21             relu        0.01                    (50,)        lbfgs   \n",
      "22             relu        0.01                    (50,)          sgd   \n",
      "23             relu        0.01                    (50,)         adam   \n",
      "24             relu        0.01                   (100,)        lbfgs   \n",
      "25             relu        0.01                   (100,)          sgd   \n",
      "26             relu        0.01                   (100,)         adam   \n",
      "27             tanh      0.0001                    (10,)        lbfgs   \n",
      "28             tanh      0.0001                    (10,)          sgd   \n",
      "29             tanh      0.0001                    (10,)         adam   \n",
      "30             tanh      0.0001                    (50,)        lbfgs   \n",
      "31             tanh      0.0001                    (50,)          sgd   \n",
      "32             tanh      0.0001                    (50,)         adam   \n",
      "33             tanh      0.0001                   (100,)        lbfgs   \n",
      "34             tanh      0.0001                   (100,)          sgd   \n",
      "35             tanh      0.0001                   (100,)         adam   \n",
      "36             tanh       0.001                    (10,)        lbfgs   \n",
      "37             tanh       0.001                    (10,)          sgd   \n",
      "38             tanh       0.001                    (10,)         adam   \n",
      "39             tanh       0.001                    (50,)        lbfgs   \n",
      "40             tanh       0.001                    (50,)          sgd   \n",
      "41             tanh       0.001                    (50,)         adam   \n",
      "42             tanh       0.001                   (100,)        lbfgs   \n",
      "43             tanh       0.001                   (100,)          sgd   \n",
      "44             tanh       0.001                   (100,)         adam   \n",
      "45             tanh        0.01                    (10,)        lbfgs   \n",
      "46             tanh        0.01                    (10,)          sgd   \n",
      "47             tanh        0.01                    (10,)         adam   \n",
      "48             tanh        0.01                    (50,)        lbfgs   \n",
      "49             tanh        0.01                    (50,)          sgd   \n",
      "50             tanh        0.01                    (50,)         adam   \n",
      "51             tanh        0.01                   (100,)        lbfgs   \n",
      "52             tanh        0.01                   (100,)          sgd   \n",
      "53             tanh        0.01                   (100,)         adam   \n",
      "\n",
      "                                               params  split0_test_score  ...  \\\n",
      "0   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.397097  ...   \n",
      "1   {'activation': 'relu', 'alpha': 0.0001, 'hidde...      -46649.507025  ...   \n",
      "2   {'activation': 'relu', 'alpha': 0.0001, 'hidde...          -4.465771  ...   \n",
      "3   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.390099  ...   \n",
      "4   {'activation': 'relu', 'alpha': 0.0001, 'hidde...          -0.001224  ...   \n",
      "5   {'activation': 'relu', 'alpha': 0.0001, 'hidde...          -4.230625  ...   \n",
      "6   {'activation': 'relu', 'alpha': 0.0001, 'hidde...           0.394205  ...   \n",
      "7   {'activation': 'relu', 'alpha': 0.0001, 'hidde...      -29980.398113  ...   \n",
      "8   {'activation': 'relu', 'alpha': 0.0001, 'hidde...          -3.760041  ...   \n",
      "9   {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.387432  ...   \n",
      "10  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -0.001141  ...   \n",
      "11  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -4.481885  ...   \n",
      "12  {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.402571  ...   \n",
      "13  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -0.001205  ...   \n",
      "14  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -4.157630  ...   \n",
      "15  {'activation': 'relu', 'alpha': 0.001, 'hidden...           0.366201  ...   \n",
      "16  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -0.106621  ...   \n",
      "17  {'activation': 'relu', 'alpha': 0.001, 'hidden...          -3.612576  ...   \n",
      "18  {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.392628  ...   \n",
      "19  {'activation': 'relu', 'alpha': 0.01, 'hidden_...      -32534.713351  ...   \n",
      "20  {'activation': 'relu', 'alpha': 0.01, 'hidden_...          -4.481599  ...   \n",
      "21  {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.396037  ...   \n",
      "22  {'activation': 'relu', 'alpha': 0.01, 'hidden_...          -0.001163  ...   \n",
      "23  {'activation': 'relu', 'alpha': 0.01, 'hidden_...          -4.157957  ...   \n",
      "24  {'activation': 'relu', 'alpha': 0.01, 'hidden_...           0.396173  ...   \n",
      "25  {'activation': 'relu', 'alpha': 0.01, 'hidden_...         -76.242643  ...   \n",
      "26  {'activation': 'relu', 'alpha': 0.01, 'hidden_...          -3.620476  ...   \n",
      "27  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...           0.163191  ...   \n",
      "28  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -0.001261  ...   \n",
      "29  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -4.555918  ...   \n",
      "30  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -0.001207  ...   \n",
      "31  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -0.003437  ...   \n",
      "32  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -4.546359  ...   \n",
      "33  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -0.001207  ...   \n",
      "34  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -0.004535  ...   \n",
      "35  {'activation': 'tanh', 'alpha': 0.0001, 'hidde...          -4.534474  ...   \n",
      "36  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.001207  ...   \n",
      "37  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.000983  ...   \n",
      "38  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -4.555902  ...   \n",
      "39  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.001208  ...   \n",
      "40  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.001014  ...   \n",
      "41  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -4.546389  ...   \n",
      "42  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.001207  ...   \n",
      "43  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -0.000258  ...   \n",
      "44  {'activation': 'tanh', 'alpha': 0.001, 'hidden...          -4.534606  ...   \n",
      "45  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -0.001207  ...   \n",
      "46  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -0.001428  ...   \n",
      "47  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -4.555916  ...   \n",
      "48  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...           0.197050  ...   \n",
      "49  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -0.002755  ...   \n",
      "50  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -4.546355  ...   \n",
      "51  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -0.001208  ...   \n",
      "52  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -0.000002  ...   \n",
      "53  {'activation': 'tanh', 'alpha': 0.01, 'hidden_...          -4.534564  ...   \n",
      "\n",
      "    split3_test_score  split4_test_score  split5_test_score  \\\n",
      "0            0.384978           0.408054           0.368316   \n",
      "1        -1436.803314      -47844.803643      -40034.994770   \n",
      "2           -4.626809          -5.073671          -4.535233   \n",
      "3            0.377923           0.431719           0.342454   \n",
      "4          -22.014743          -0.000775          -0.000164   \n",
      "5           -4.237105          -4.756056          -4.254578   \n",
      "6            0.371602           0.426064           0.326060   \n",
      "7           -0.003825          -0.000809          -0.237840   \n",
      "8           -3.782288          -4.336228          -3.797900   \n",
      "9            0.395202           0.427143           0.333029   \n",
      "10       -7111.255651          -0.000800      -17901.373264   \n",
      "11          -4.641286          -5.091918          -4.597446   \n",
      "12           0.389218           0.429153           0.344344   \n",
      "13          -0.003986          -0.000774          -0.000180   \n",
      "14          -4.339559          -4.721791          -4.233673   \n",
      "15           0.380887           0.395611           0.337813   \n",
      "16          -0.003998          -0.000752          -0.000200   \n",
      "17          -3.788636          -4.183112          -3.647083   \n",
      "18           0.390509           0.418748           0.369360   \n",
      "19       -7842.617452      -42628.192477      -34033.643987   \n",
      "20          -4.672219          -5.092197          -4.582727   \n",
      "21           0.364121           0.401519           0.372642   \n",
      "22          -7.919532       -1618.424625       -5900.021393   \n",
      "23          -4.325384          -4.771834          -4.233486   \n",
      "24           0.335885           0.435478           0.358746   \n",
      "25          -0.003956          -1.270196          -0.000182   \n",
      "26          -3.833129          -4.129210          -3.821665   \n",
      "27          -0.003935          -0.000763          -0.000171   \n",
      "28          -0.004186          -0.000266          -0.000634   \n",
      "29          -4.717487          -5.194912          -4.627363   \n",
      "30          -0.003935           0.191390          -0.000171   \n",
      "31          -0.003910          -0.000219          -0.000421   \n",
      "32          -4.707624          -5.183984          -4.617521   \n",
      "33          -0.003935          -0.000763          -0.000171   \n",
      "34          -0.013276          -0.002089          -0.000447   \n",
      "35          -4.695547          -5.170357          -4.605482   \n",
      "36          -0.003935          -0.000763          -0.000171   \n",
      "37          -0.004080          -0.000501          -0.000250   \n",
      "38          -4.717341          -5.195028          -4.627579   \n",
      "39           0.229643           0.302600          -0.000171   \n",
      "40          -0.004022          -0.000346          -0.000378   \n",
      "41          -4.707554          -5.183973          -4.617550   \n",
      "42          -0.003935           0.304638           0.295744   \n",
      "43          -0.003545          -0.000635          -0.000430   \n",
      "44          -4.695398          -5.170375          -4.605485   \n",
      "45           0.185758           0.225095          -0.000171   \n",
      "46          -0.003958          -0.000443          -0.000002   \n",
      "47          -4.717396          -5.195012          -4.627383   \n",
      "48          -0.003935          -0.000763          -0.000172   \n",
      "49          -0.003597          -0.000866          -0.000593   \n",
      "50          -4.707604          -5.184009          -4.617496   \n",
      "51           0.047357          -0.000760          -0.000171   \n",
      "52          -0.000325          -0.000746          -0.001037   \n",
      "53          -4.695458          -5.170539          -4.605476   \n",
      "\n",
      "    split6_test_score  split7_test_score  split8_test_score  \\\n",
      "0            0.439453       4.266170e-01           0.546723   \n",
      "1           -0.000050      -7.180660e+10       -9527.992105   \n",
      "2           -4.889198      -4.790088e+00          -4.324747   \n",
      "3            0.431094       4.002821e-01           0.542282   \n",
      "4       -32983.050696      -8.333665e-03          -4.795630   \n",
      "5           -4.625364      -4.481567e+00          -4.039569   \n",
      "6            0.379496       3.941799e-01           0.540267   \n",
      "7           -0.000060      -8.282922e-03          -0.009027   \n",
      "8           -4.031227      -4.003450e+00          -3.413315   \n",
      "9            0.445460       4.107189e-01           0.545641   \n",
      "10       -4133.770137      -2.840959e+04      -35294.282078   \n",
      "11          -4.905159      -4.838433e+00          -4.340315   \n",
      "12           0.387045       4.104286e-01           0.543353   \n",
      "13          -0.600828      -8.562151e-03         -22.171589   \n",
      "14          -4.625032      -4.497466e+00          -3.980470   \n",
      "15           0.380600       4.198919e-01           0.482290   \n",
      "16          -0.000061      -4.278161e+01          -0.008887   \n",
      "17          -4.127515      -3.972373e+00          -3.518772   \n",
      "18           0.439060       4.093250e-01           0.537225   \n",
      "19          -0.000056      -1.868191e-01       -9892.717382   \n",
      "20          -4.870958      -4.838677e+00          -4.357968   \n",
      "21           0.395728       4.117056e-01           0.545146   \n",
      "22          -0.000063      -8.433742e-03      -13302.136131   \n",
      "23          -4.707059      -4.453581e+00          -3.996738   \n",
      "24           0.386023       4.167123e-01           0.539170   \n",
      "25      -33808.171542      -2.814159e+02          -0.009167   \n",
      "26          -4.099699      -4.032904e+00          -3.601041   \n",
      "27          -0.000058       2.465032e-01          -0.009133   \n",
      "28          -0.000005      -7.655783e-03          -0.010263   \n",
      "29          -5.024060      -4.901169e+00          -4.432537   \n",
      "30          -0.000058      -8.395629e-03           0.350602   \n",
      "31          -0.000065      -1.922069e-03          -0.007215   \n",
      "32          -5.013325      -4.890959e+00          -4.422630   \n",
      "33          -0.000058      -8.395655e-03          -0.009133   \n",
      "34          -0.001991      -1.021883e-02          -0.013296   \n",
      "35          -5.000171      -4.878602e+00          -4.410555   \n",
      "36          -0.000058       2.167381e-01          -0.009133   \n",
      "37          -0.000331      -8.698593e-03          -0.008195   \n",
      "38          -5.024176      -4.901002e+00          -4.432685   \n",
      "39           0.205547       3.395730e-04           0.019039   \n",
      "40          -0.000007      -8.485563e-03          -0.016445   \n",
      "41          -5.013287      -4.891129e+00          -4.422568   \n",
      "42          -0.000058       3.109635e-03          -0.009133   \n",
      "43          -0.000859      -1.444792e-02          -0.000199   \n",
      "44          -5.000033      -4.878669e+00          -4.410601   \n",
      "45          -0.000058      -8.395847e-03           0.292556   \n",
      "46          -0.000001      -8.349053e-03          -0.008639   \n",
      "47          -5.024051      -4.901155e+00          -4.432542   \n",
      "48          -0.000058      -8.397090e-03          -0.009133   \n",
      "49          -0.000169      -9.164597e-03          -0.019016   \n",
      "50          -5.013347      -4.891015e+00          -4.422688   \n",
      "51           0.315214      -8.395524e-03           0.347583   \n",
      "52          -0.000089      -1.236426e-03          -0.011372   \n",
      "53          -5.000051      -4.878600e+00          -4.410606   \n",
      "\n",
      "    split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.495450     4.210370e-01    5.799258e-02                1  \n",
      "1        -1162.843961    -7.180679e+09    2.154197e+10               54  \n",
      "2           -4.630756    -4.690133e+00    2.099346e-01               35  \n",
      "3            0.492536     4.127572e-01    6.319206e-02                5  \n",
      "4         -232.262101    -3.508218e+03    9.839791e+03               50  \n",
      "5           -4.179172    -4.357091e+00    2.063671e-01               33  \n",
      "6            0.468437     3.949941e-01    6.555807e-02                8  \n",
      "7           -0.002790    -3.581616e+03    8.969936e+03               51  \n",
      "8           -3.797079    -3.872711e+00    2.264569e-01               29  \n",
      "9            0.485073     4.160954e-01    6.100844e-02                2  \n",
      "10      -23469.641923    -1.391793e+04    1.255865e+04               52  \n",
      "11          -4.598055    -4.702768e+00    2.064565e-01               37  \n",
      "12           0.491389     4.133700e-01    6.186298e-02                4  \n",
      "13          -0.002849    -5.745290e+00    1.167250e+01               47  \n",
      "14          -4.330562    -4.373807e+00    2.115828e-01               34  \n",
      "15           0.461561     3.937654e-01    4.697206e-02                9  \n",
      "16          -0.002844    -4.291902e+00    1.282994e+01               31  \n",
      "17          -3.827515    -3.848281e+00    2.058100e-01               28  \n",
      "18           0.472251     4.147951e-01    5.416856e-02                3  \n",
      "19       -8577.421551    -1.562366e+04    1.480500e+04               53  \n",
      "20          -4.597150    -4.695684e+00    1.993700e-01               36  \n",
      "21           0.489789     4.106388e-01    6.061037e-02                6  \n",
      "22          -0.002733    -2.082853e+03    4.135138e+03               48  \n",
      "23          -4.192813    -4.355234e+00    2.307314e-01               32  \n",
      "24           0.485566     4.045647e-01    6.417603e-02                7  \n",
      "25          -0.002813    -3.416713e+03    1.013084e+04               49  \n",
      "26          -3.813360    -3.875105e+00    1.745785e-01               30  \n",
      "27          -0.002827     5.640844e-02    9.479873e-02               15  \n",
      "28          -0.003469    -4.248064e-03    4.576247e-03               24  \n",
      "29          -4.694067    -4.782571e+00    2.153452e-01               44  \n",
      "30           0.324759     1.130570e-01    1.489922e-01               11  \n",
      "31          -0.001326    -3.305531e-03    4.315605e-03               20  \n",
      "32          -4.683743    -4.772322e+00    2.149941e-01               41  \n",
      "33          -0.002826     2.148316e-02    7.363309e-02               17  \n",
      "34          -0.002631    -7.400106e-03    6.803596e-03               27  \n",
      "35          -4.671162    -4.759764e+00    2.145256e-01               39  \n",
      "36          -0.002826     1.846347e-02    6.621850e-02               18  \n",
      "37          -0.002724    -3.945633e-03    4.198582e-03               22  \n",
      "38          -4.693978    -4.782590e+00    2.153462e-01               46  \n",
      "39           0.336190     1.325817e-01    1.361376e-01               10  \n",
      "40          -0.009188    -4.867028e-03    5.332200e-03               25  \n",
      "41          -4.683730    -4.772348e+00    2.150122e-01               43  \n",
      "42          -0.002826     8.198241e-02    1.319766e-01               12  \n",
      "43          -0.003242    -4.014693e-03    5.646591e-03               23  \n",
      "44          -4.671048    -4.759734e+00    2.145022e-01               38  \n",
      "45          -0.002826     6.767410e-02    1.119012e-01               14  \n",
      "46          -0.003434    -3.934786e-03    4.083220e-03               21  \n",
      "47          -4.694041    -4.782572e+00    2.153668e-01               45  \n",
      "48          -0.002826     3.896635e-02    8.796394e-02               16  \n",
      "49          -0.007730    -6.159920e-03    6.764511e-03               26  \n",
      "50          -4.683791    -4.772347e+00    2.149976e-01               42  \n",
      "51          -0.002826     6.827843e-02    1.326841e-01               13  \n",
      "52          -0.000107    -2.632576e-03    4.164013e-03               19  \n",
      "53          -4.671132    -4.759767e+00    2.145382e-01               40  \n",
      "\n",
      "[54 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "regressor = MLPRegressor()\n",
    "\n",
    "parameters = {\n",
    "    \"hidden_layer_sizes\" : [(10,), (50,), (100,)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"solver\" : [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    'alpha': [0.0001, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "#Prüfen welches sinnvoller ist in Bezug auf Regression. Laut ChatGPT ist es KFold.\n",
    "k_10_fold_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search_estimator = GridSearchCV(regressor, parameters, scoring='r2', cv=k_10_fold_cv, return_train_score=False)\n",
    "\n",
    "grid_search_estimator.fit(df_preprocessed,target)\n",
    "\n",
    "#results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "    \n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(grid_search_estimator.best_score_, grid_search_estimator.best_params_))\n",
    "\n",
    "results = pd.DataFrame(grid_search_estimator.cv_results_)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7f896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
